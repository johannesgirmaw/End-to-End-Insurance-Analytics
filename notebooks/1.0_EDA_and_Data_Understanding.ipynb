{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9950a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/yohannes/10Academy/Week3/End-to-End-Insurance-Analytics/notebooks/../data/MachineLearningRating_v3.txt\n",
      "Initial data load successful. Performing initial preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_272575/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_272575/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_272575/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_272575/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_272575/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial preprocessing complete.\n",
      "\n",
      "ERROR: Parquet engine not found.\n",
      "Please install 'pyarrow' or 'fastparquet' to save data in Parquet format.\n",
      "You can install pyarrow using: pip install pyarrow\n"
     ]
    }
   ],
   "source": [
    "# data_ingestion.py (Updated)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the raw insurance data from a pipe-delimited TXT file,\n",
    "    performs initial data type conversions, and handles some basic cleaning.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the raw data file (e.g., 'root/data/ml.txt').\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Data file not found at: {file_path}\")\n",
    "\n",
    "    print(f\"Loading data from: {file_path}\")\n",
    "    # Use low_memory=False to potentially resolve DtypeWarning during initial read\n",
    "    df = pd.read_csv(file_path, sep='|', encoding='utf-8', low_memory=False)\n",
    "\n",
    "    print(\"Initial data load successful. Performing initial preprocessing...\")\n",
    "\n",
    "    # --- Date Conversions ---\n",
    "    # TransactionMonth: YYYY-MM-DD HH:MM:SS format\n",
    "    df['TransactionMonth'] = pd.to_datetime(\n",
    "        df['TransactionMonth'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    # VehicleIntroDate: M/YYYY format\n",
    "    df['VehicleIntroDate'] = pd.to_datetime(\n",
    "        df['VehicleIntroDate'], format='%m/%Y', errors='coerce')\n",
    "\n",
    "    # --- Numerical Conversions ---\n",
    "    numerical_cols = [\n",
    "        'Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors',\n",
    "        'CustomValueEstimate', 'CapitalOutstanding', 'NumberOfVehiclesInFleet',\n",
    "        'SumInsured', 'CalculatedPremiumPerTerm', 'TotalPremium', 'TotalClaims'\n",
    "    ]\n",
    "    for col in numerical_cols:\n",
    "        # Replace empty strings or spaces with NaN before converting to numeric\n",
    "        df[col] = df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        # Convert to numeric, coercing errors. Convert to float to handle NaNs.\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "\n",
    "    # --- String Cleaning and Categorical Conversion ---\n",
    "    string_cols = df.select_dtypes(include='object').columns\n",
    "    for col in string_cols:\n",
    "        # These are handled by boolean_map later\n",
    "        if col not in ['WrittenOff', 'Rebuilt', 'Converted']:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "            # Replace 'Not specified', empty strings, or strings with only spaces with NaN\n",
    "            df[col] = df[col].replace(['Not specified', '', ' '], np.nan)\n",
    "\n",
    "    # --- Boolean Conversion for Yes/No columns ---\n",
    "    boolean_map = {'Yes': True, 'No': False}\n",
    "    # Columns 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder' are often boolean-like\n",
    "    # Also include 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle'\n",
    "    bool_cols_to_process = [\n",
    "        'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle', 'WrittenOff',\n",
    "        'Rebuilt', 'Converted', 'CrossBorder'\n",
    "    ]\n",
    "    for col in bool_cols_to_process:\n",
    "        # Map values, then fill NaNs with False and explicitly convert to boolean dtype\n",
    "        df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
    "\n",
    "    # Convert object columns that should be categorical to 'category' dtype for memory efficiency\n",
    "    # Exclude columns that are likely IDs or unique identifiers\n",
    "    id_cols = ['UnderwrittenCoverID', 'PolicyID', 'mmcode']\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        if col not in id_cols:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    print(\"Initial preprocessing complete.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the path to your data file\n",
    "    # In a script, __file__ works well.\n",
    "    data_dir = os.path.join(os.path.dirname(\n",
    "        os.path.abspath('MachineLearningRating_v3.txt')), '../data')\n",
    "    input_file_path = os.path.join(data_dir, 'MachineLearningRating_v3.txt')\n",
    "    # Using parquet for efficiency\n",
    "    output_file_path = os.path.join(data_dir, 'processed_ml_data.parquet')\n",
    "\n",
    "    # Ensure the data directory exists\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        processed_df = load_and_preprocess_data(input_file_path)\n",
    "\n",
    "        # Save the processed data for easier loading in EDA notebook\n",
    "        processed_df.to_parquet(output_file_path, index=False)\n",
    "        print(f\"Processed data saved to: {output_file_path}\")\n",
    "        print(f\"Processed DataFrame shape: {processed_df.shape}\")\n",
    "        print(f\"Processed DataFrame info:\\n{processed_df.info()}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        print(\"Please ensure the 'ml.txt' file is located in a 'data' directory at the root of your project.\")\n",
    "    except ImportError:\n",
    "        print(\"\\nERROR: Parquet engine not found.\")\n",
    "        print(\"Please install 'pyarrow' or 'fastparquet' to save data in Parquet format.\")\n",
    "        print(\"You can install pyarrow using: pip install pyarrow\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during data processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e79c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
