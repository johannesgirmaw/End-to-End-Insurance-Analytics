{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9950a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/yohannes/10Academy/Week3/End-to-End-Insurance-Analytics/notebooks/../data/MachineLearningRating_v3.txt\n",
      "Initial data load successful. Performing initial preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25151/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_25151/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_25151/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_25151/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
      "/tmp/ipykernel_25151/822900066.py:67: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial preprocessing complete.\n",
      "Processed data saved to: /home/yohannes/10Academy/Week3/End-to-End-Insurance-Analytics/notebooks/../data/processed_ml_data.parquet\n",
      "Processed DataFrame shape: (1000098, 52)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000098 entries, 0 to 1000097\n",
      "Data columns (total 52 columns):\n",
      " #   Column                    Non-Null Count    Dtype         \n",
      "---  ------                    --------------    -----         \n",
      " 0   UnderwrittenCoverID       1000098 non-null  int64         \n",
      " 1   PolicyID                  1000098 non-null  int64         \n",
      " 2   TransactionMonth          1000098 non-null  datetime64[ns]\n",
      " 3   IsVATRegistered           1000098 non-null  bool          \n",
      " 4   Citizenship               104888 non-null   category      \n",
      " 5   LegalType                 1000098 non-null  category      \n",
      " 6   Title                     1000098 non-null  category      \n",
      " 7   Language                  1000098 non-null  category      \n",
      " 8   Bank                      1000098 non-null  category      \n",
      " 9   AccountType               1000098 non-null  category      \n",
      " 10  MaritalStatus             13890 non-null    category      \n",
      " 11  Gender                    59108 non-null    category      \n",
      " 12  Country                   1000098 non-null  category      \n",
      " 13  Province                  1000098 non-null  category      \n",
      " 14  PostalCode                1000098 non-null  int64         \n",
      " 15  MainCrestaZone            1000098 non-null  category      \n",
      " 16  SubCrestaZone             1000098 non-null  category      \n",
      " 17  ItemType                  1000098 non-null  category      \n",
      " 18  mmcode                    999546 non-null   float64       \n",
      " 19  VehicleType               1000098 non-null  category      \n",
      " 20  RegistrationYear          1000098 non-null  int64         \n",
      " 21  make                      1000098 non-null  category      \n",
      " 22  Model                     1000098 non-null  category      \n",
      " 23  Cylinders                 999546 non-null   float64       \n",
      " 24  cubiccapacity             999546 non-null   float64       \n",
      " 25  kilowatts                 999546 non-null   float64       \n",
      " 26  bodytype                  1000098 non-null  category      \n",
      " 27  NumberOfDoors             999546 non-null   float64       \n",
      " 28  VehicleIntroDate          951337 non-null   datetime64[ns]\n",
      " 29  CustomValueEstimate       220456 non-null   float64       \n",
      " 30  AlarmImmobiliser          1000098 non-null  bool          \n",
      " 31  TrackingDevice            1000098 non-null  bool          \n",
      " 32  CapitalOutstanding        999776 non-null   float64       \n",
      " 33  NewVehicle                1000098 non-null  bool          \n",
      " 34  WrittenOff                1000098 non-null  bool          \n",
      " 35  Rebuilt                   1000098 non-null  bool          \n",
      " 36  Converted                 1000098 non-null  bool          \n",
      " 37  CrossBorder               1000098 non-null  bool          \n",
      " 38  NumberOfVehiclesInFleet   0 non-null        float64       \n",
      " 39  SumInsured                1000098 non-null  float64       \n",
      " 40  TermFrequency             1000098 non-null  category      \n",
      " 41  CalculatedPremiumPerTerm  1000098 non-null  float64       \n",
      " 42  ExcessSelected            1000098 non-null  category      \n",
      " 43  CoverCategory             1000098 non-null  category      \n",
      " 44  CoverType                 1000098 non-null  category      \n",
      " 45  CoverGroup                1000098 non-null  category      \n",
      " 46  Section                   1000098 non-null  category      \n",
      " 47  Product                   1000098 non-null  category      \n",
      " 48  StatutoryClass            1000098 non-null  category      \n",
      " 49  StatutoryRiskType         1000098 non-null  category      \n",
      " 50  TotalPremium              1000098 non-null  float64       \n",
      " 51  TotalClaims               1000098 non-null  float64       \n",
      "dtypes: bool(8), category(26), datetime64[ns](2), float64(12), int64(4)\n",
      "memory usage: 170.8 MB\n",
      "Processed DataFrame info:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# data_ingestion.py (Updated)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the raw insurance data from a pipe-delimited TXT file,\n",
    "    performs initial data type conversions, and handles some basic cleaning.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the raw data file (e.g., 'root/data/ml.txt').\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Data file not found at: {file_path}\")\n",
    "\n",
    "    print(f\"Loading data from: {file_path}\")\n",
    "    # Use low_memory=False to potentially resolve DtypeWarning during initial read\n",
    "    df = pd.read_csv(file_path, sep='|', encoding='utf-8', low_memory=False)\n",
    "\n",
    "    print(\"Initial data load successful. Performing initial preprocessing...\")\n",
    "\n",
    "    # --- Date Conversions ---\n",
    "    # TransactionMonth: YYYY-MM-DD HH:MM:SS format\n",
    "    df['TransactionMonth'] = pd.to_datetime(\n",
    "        df['TransactionMonth'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    # VehicleIntroDate: M/YYYY format\n",
    "    df['VehicleIntroDate'] = pd.to_datetime(\n",
    "        df['VehicleIntroDate'], format='%m/%Y', errors='coerce')\n",
    "\n",
    "    # --- Numerical Conversions ---\n",
    "    numerical_cols = [\n",
    "        'Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors',\n",
    "        'CustomValueEstimate', 'CapitalOutstanding', 'NumberOfVehiclesInFleet',\n",
    "        'SumInsured', 'CalculatedPremiumPerTerm', 'TotalPremium', 'TotalClaims'\n",
    "    ]\n",
    "    for col in numerical_cols:\n",
    "        # Replace empty strings or spaces with NaN before converting to numeric\n",
    "        df[col] = df[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        # Convert to numeric, coercing errors. Convert to float to handle NaNs.\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "\n",
    "    # --- String Cleaning and Categorical Conversion ---\n",
    "    string_cols = df.select_dtypes(include='object').columns\n",
    "    for col in string_cols:\n",
    "        # These are handled by boolean_map later\n",
    "        if col not in ['WrittenOff', 'Rebuilt', 'Converted']:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "            # Replace 'Not specified', empty strings, or strings with only spaces with NaN\n",
    "            df[col] = df[col].replace(['Not specified', '', ' '], np.nan)\n",
    "\n",
    "    # --- Boolean Conversion for Yes/No columns ---\n",
    "    boolean_map = {'Yes': True, 'No': False}\n",
    "    # Columns 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder' are often boolean-like\n",
    "    # Also include 'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle'\n",
    "    bool_cols_to_process = [\n",
    "        'AlarmImmobiliser', 'TrackingDevice', 'NewVehicle', 'WrittenOff',\n",
    "        'Rebuilt', 'Converted', 'CrossBorder'\n",
    "    ]\n",
    "    for col in bool_cols_to_process:\n",
    "        # Map values, then fill NaNs with False and explicitly convert to boolean dtype\n",
    "        df[col] = df[col].map(boolean_map).fillna(False).astype(bool)\n",
    "\n",
    "    # Convert object columns that should be categorical to 'category' dtype for memory efficiency\n",
    "    # Exclude columns that are likely IDs or unique identifiers\n",
    "    id_cols = ['UnderwrittenCoverID', 'PolicyID', 'mmcode']\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        if col not in id_cols:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    print(\"Initial preprocessing complete.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the path to your data file\n",
    "    # In a script, __file__ works well.\n",
    "    data_dir = os.path.join(os.path.dirname(\n",
    "        os.path.abspath('MachineLearningRating_v3.txt')), '../data')\n",
    "    input_file_path = os.path.join(data_dir, 'MachineLearningRating_v3.txt')\n",
    "    # Using parquet for efficiency\n",
    "    output_file_path = os.path.join(data_dir, 'processed_ml_data.parquet')\n",
    "\n",
    "    # Ensure the data directory exists\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        processed_df = load_and_preprocess_data(input_file_path)\n",
    "\n",
    "        # Save the processed data for easier loading in EDA notebook\n",
    "        processed_df.to_parquet(output_file_path, index=False)\n",
    "        print(f\"Processed data saved to: {output_file_path}\")\n",
    "        print(f\"Processed DataFrame shape: {processed_df.shape}\")\n",
    "        print(f\"Processed DataFrame info:\\n{processed_df.info()}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        print(\"Please ensure the 'ml.txt' file is located in a 'data' directory at the root of your project.\")\n",
    "    except ImportError:\n",
    "        print(\"\\nERROR: Parquet engine not found.\")\n",
    "        print(\"Please install 'pyarrow' or 'fastparquet' to save data in Parquet format.\")\n",
    "        print(\"You can install pyarrow using: pip install pyarrow\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during data processing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
